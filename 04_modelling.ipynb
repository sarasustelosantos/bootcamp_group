{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "## 1. Prepare for Modelling\n",
    "### 1.1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Data Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir pelo df do feature selection \n",
    "all_data = pd.read_csv('data/processed/df_clustered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer ID', 'Age', 'Under 30', 'Senior Citizen', 'Married',\n",
       "       'Dependents', 'Number of Dependents', 'City', 'Referred a Friend',\n",
       "       'Number of Referrals', 'Tenure in Months', 'Tenure Category',\n",
       "       'Phone Service', 'Avg Monthly Long Distance Charges', 'Multiple Lines',\n",
       "       'Internet Service', 'Avg Monthly GB Download', 'Online Security',\n",
       "       'Online Backup', 'Device Protection Plan', 'Premium Tech Support',\n",
       "       'Streaming TV', 'Streaming Movies', 'Streaming Music', 'Unlimited Data',\n",
       "       'Paperless Billing', 'Monthly Charge', 'Total Charges', 'Total Refunds',\n",
       "       'Total Extra Data Charges', 'Total Long Distance Charges',\n",
       "       'Total Revenue', 'Satisfaction Score', 'New Customer', 'Churn Label',\n",
       "       'Churn Score', 'CLTV', 'Churn Reason', 'Population', 'Engagement Score',\n",
       "       'Gender_Male', 'Offer_Offer A', 'Offer_Offer B', 'Offer_Offer C',\n",
       "       'Offer_Offer D', 'Offer_Offer E', 'Internet Type_Cable',\n",
       "       'Internet Type_DSL', 'Internet Type_Fiber Optic',\n",
       "       'Payment Method_Bank Withdrawal', 'Payment Method_Credit Card',\n",
       "       'Churn Category_Attitude', 'Churn Category_Competitor',\n",
       "       'Churn Category_Dissatisfaction', 'Churn Category_Price',\n",
       "       'Density_High', 'Density_Low', 'Contract_Month-to-Month',\n",
       "       'Contract_One Year', 'Contract_Two Year', 'Cluster_Demo', 'Cluster_SVC',\n",
       "       'Cluster_Streaming', 'Cluster_Tenure', 'Cluster_Payment',\n",
       "       'Cluster_Profit', 'Cluster_Overall', 'Cluster_Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant variables for prediction (cluster) \n",
    "columns_to_remove=[col for col in all_data.columns if col.startswith('Cluster_')]\n",
    "all_data.drop(columns=columns_to_remove, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scenarios generated in feature selection\n",
    "scenario1_td = pd.read_csv('data/processed/scenario1.csv')\n",
    "scenario2_td = pd.read_csv('data/processed/scenario2.csv')\n",
    "\n",
    "# Other scenarios created in this notebook\n",
    "\n",
    "scenario3 = all_data[['Senior Citizen','Dependents','Referred a Friend','Internet Service','Internet Type_Fiber Optic','Online Security','Offer_Offer E',\n",
    "                     'Offer_Offer A','Premium Tech Support','Unlimited Data','Contract_Month-to-Month','Paperless Billing','Payment Method_Credit Card', 'Churn Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Data Split\n",
    "> Train-Test split<p>\n",
    "> Train data in predictors (X) and target variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scenario to test\n",
    "df = scenario1_td.copy()\n",
    "df.set_index(\"Customer ID\", inplace=True)\n",
    "\n",
    "# Split\n",
    "X_total = df\n",
    "y_total = all_data[[\"Customer ID\", \"Churn Label\"]]\n",
    "y_total.set_index(\"Customer ID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data into Train and test with 20% test Data. Stratify dut to unbalance Dataset. (Only 27% Churn)\n",
    "X_train_total, X_test, y_train_total, y_test = train_test_split(X_total, y_total, test_size=0.20, random_state=1, stratify=y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to append the metrics of all the models\n",
    "models =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Models\n",
    "### 2.1 Logistic Regression - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.974, 0.972, 0.975, 0.973, 0.972]\n",
      "Mean Accuracy: 0.973\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.951, 0.946, 0.953, 0.949, 0.948]\n",
      "Mean F1: 0.949\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.97, 0.977, 0.968, 0.974, 0.978]\n",
      "Mean Accuracy: 0.973\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.943, 0.956, 0.939, 0.95, 0.958]\n",
      "Mean F1: 0.949\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling - scenario 1 already scaled\n",
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_LR = LogisticRegression()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_LR.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_LR.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_LR.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.98\n",
      "Test F1 Scores: 0.962\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_LR.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_LR.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = {\"Model\": \"Logistic Regression\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision Tree - Train and Validation Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.972, 0.972, 0.973, 0.972, 0.971]\n",
      "Mean Accuracy: 0.972\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.945, 0.943, 0.946, 0.945, 0.942]\n",
      "Mean F1: 0.944\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.97, 0.973, 0.969, 0.971, 0.977]\n",
      "Mean Accuracy: 0.972\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.94, 0.947, 0.938, 0.942, 0.955]\n",
      "Mean F1: 0.944\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_DT = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_DT.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_DT.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_DT.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision Tree - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.974\n",
      "Test F1 Scores: 0.949\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_DT.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_DT.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = {\"Model\": \"Decision Tree\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Random Forest - Train and Validation Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.972, 0.972, 0.973, 0.972, 0.971]\n",
      "Mean Accuracy: 0.972\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.945, 0.943, 0.946, 0.945, 0.942]\n",
      "Mean F1: 0.944\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.97, 0.973, 0.969, 0.971, 0.977]\n",
      "Mean Accuracy: 0.972\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.94, 0.947, 0.938, 0.942, 0.955]\n",
      "Mean F1: 0.944\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_RF = RandomForestClassifier(max_depth=3)\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_DT.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_DT.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_DT.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Random Forest - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.974\n",
      "Test F1 Scores: 0.949\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_RF.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_RF.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = {\"Model\": \"Random Forest\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 SVC - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.978, 0.975, 0.978, 0.976, 0.976]\n",
      "Mean Accuracy: 0.977\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.958, 0.953, 0.958, 0.954, 0.956]\n",
      "Mean F1: 0.956\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.973, 0.979, 0.972, 0.974, 0.98]\n",
      "Mean Accuracy: 0.976\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.95, 0.96, 0.947, 0.951, 0.962]\n",
      "Mean F1: 0.954\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_SVC = SVC()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_SVC.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_SVC.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_SVC.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 SVC - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.982\n",
      "Test F1 Scores: 0.967\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_SVC.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_SVC.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcc = {\"Model\": \"SVC\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(svcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Gaussian - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.959, 0.958, 0.96, 0.959, 0.959]\n",
      "Mean Accuracy: 0.959\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.923, 0.922, 0.924, 0.924, 0.924]\n",
      "Mean F1: 0.923\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.96, 0.96, 0.958, 0.962, 0.959]\n",
      "Mean Accuracy: 0.96\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.926, 0.925, 0.922, 0.928, 0.925]\n",
      "Mean F1: 0.925\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_GA = GaussianNB()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_GA.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_GA.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_GA.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Gaussian - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.963\n",
      "Test F1 Scores: 0.931\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_GA.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_GA.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = {\"Model\": \"Gaussian\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 KNN - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.983, 0.981, 0.982, 0.982, 0.984]\n",
      "Mean Accuracy: 0.982\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.968, 0.964, 0.966, 0.966, 0.969]\n",
      "Mean F1: 0.967\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.97, 0.977, 0.974, 0.972, 0.977]\n",
      "Mean Accuracy: 0.974\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.943, 0.956, 0.951, 0.947, 0.956]\n",
      "Mean F1: 0.951\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_KNN = KNeighborsClassifier()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_KNN.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_KNN.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_KNN.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 KNN - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.982\n",
      "Test F1 Scores: 0.965\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_KNN.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_KNN.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = {\"Model\": \"KNN\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Gradient Boosting - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.985, 0.985, 0.987, 0.984, 0.985]\n",
      "Mean Accuracy: 0.985\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.973, 0.971, 0.976, 0.97, 0.973]\n",
      "Mean F1: 0.973\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.982, 0.985, 0.973, 0.98, 0.98]\n",
      "Mean Accuracy: 0.98\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.967, 0.972, 0.95, 0.963, 0.964]\n",
      "Mean F1: 0.963\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_GB = GradientBoostingClassifier()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_GB.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_GB.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_GB.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Gradient Boosting - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.984\n",
      "Test F1 Scores: 0.969\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_GB.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_GB.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = {\"Model\": \"Gradient Boosting\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 MLP - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.975, 0.974, 0.976, 0.976, 0.975]\n",
      "Mean Accuracy: 0.975\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.952, 0.952, 0.956, 0.954, 0.952]\n",
      "Mean F1: 0.953\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.975, 0.98, 0.97, 0.975, 0.975]\n",
      "Mean Accuracy: 0.975\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.953, 0.962, 0.944, 0.953, 0.953]\n",
      "Mean F1: 0.953\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_MLP = MLPClassifier()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_MLP.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_MLP.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_MLP.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 MLP - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.979\n",
      "Test F1 Scores: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_MLP.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_MLP.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = {\"Model\": \"MLP\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coonvert List of Models Metrics to DF\n",
    "models_df = pd.DataFrame(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Training</th>\n",
       "      <th>Accuracy Validation</th>\n",
       "      <th>Accuracy Test</th>\n",
       "      <th>F1 Training</th>\n",
       "      <th>F1 Validation</th>\n",
       "      <th>F1 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy Training  Accuracy Validation  Accuracy Test  \\\n",
       "0  Logistic Regression              0.973                0.973          0.980   \n",
       "1        Decision Tree              0.972                0.972          0.974   \n",
       "2        Random Forest              0.972                0.972          0.974   \n",
       "3             Gaussian              0.959                0.960          0.963   \n",
       "4                  KNN              0.982                0.974          0.982   \n",
       "5    Gradient Boosting              0.985                0.980          0.984   \n",
       "6                  MLP              0.975                0.975          0.979   \n",
       "\n",
       "   F1 Training  F1 Validation  F1 Test  \n",
       "0        0.949          0.949    0.962  \n",
       "1        0.944          0.944    0.949  \n",
       "2        0.944          0.944    0.949  \n",
       "3        0.923          0.925    0.931  \n",
       "4        0.967          0.951    0.965  \n",
       "5        0.973          0.963    0.969  \n",
       "6        0.953          0.953    0.960  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decision Trees:\n",
    "Intuitive and easy to understand.\n",
    "Can capture complex relationships in the data.\n",
    "\n",
    "> Random Forest:\n",
    "Ensemble method built on decision trees.\n",
    "Generally more robust and accurate than individual trees.\n",
    "\n",
    "> Support Vector Machines (SVM):\n",
    "Effective in high-dimensional spaces.\n",
    "Works well when there is a clear margin of separation between classes.\n",
    "\n",
    "> Naive Bayes:\n",
    "Assumes independence between features.\n",
    "Fast and can perform well on certain types of data.\n",
    "\n",
    "> K-Nearest Neighbors (KNN):\n",
    "Instance-based learning.\n",
    "Simple and easy to understand.\n",
    "\n",
    "> Gradient Boosting (e.g., XGBoost, LightGBM, AdaBoost):\n",
    "Builds a strong predictive model by combining weak models.\n",
    "Often produces very accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

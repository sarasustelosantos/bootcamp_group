{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "## 1. Prepare for Modelling\n",
    "### 1.1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Data Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir pelo df do feature selection \n",
    "all_data = pd.read_csv('data/processed/df_clustered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer ID', 'Age', 'Under 30', 'Senior Citizen', 'Married',\n",
       "       'Dependents', 'Number of Dependents', 'City', 'Referred a Friend',\n",
       "       'Number of Referrals', 'Tenure in Months', 'Tenure Category',\n",
       "       'Phone Service', 'Avg Monthly Long Distance Charges', 'Multiple Lines',\n",
       "       'Internet Service', 'Avg Monthly GB Download', 'Online Security',\n",
       "       'Online Backup', 'Device Protection Plan', 'Premium Tech Support',\n",
       "       'Streaming TV', 'Streaming Movies', 'Streaming Music', 'Unlimited Data',\n",
       "       'Paperless Billing', 'Monthly Charge', 'Total Charges', 'Total Refunds',\n",
       "       'Total Extra Data Charges', 'Total Long Distance Charges',\n",
       "       'Total Revenue', 'Satisfaction Score', 'New Customer', 'Churn Label',\n",
       "       'Churn Score', 'CLTV', 'Churn Reason', 'Population', 'Engagement Score',\n",
       "       'Gender_Male', 'Offer_Offer A', 'Offer_Offer B', 'Offer_Offer C',\n",
       "       'Offer_Offer D', 'Offer_Offer E', 'Internet Type_Cable',\n",
       "       'Internet Type_DSL', 'Internet Type_Fiber Optic',\n",
       "       'Payment Method_Bank Withdrawal', 'Payment Method_Credit Card',\n",
       "       'Churn Category_Attitude', 'Churn Category_Competitor',\n",
       "       'Churn Category_Dissatisfaction', 'Churn Category_Price',\n",
       "       'Density_High', 'Density_Low', 'Contract_Month-to-Month',\n",
       "       'Contract_One Year', 'Contract_Two Year', 'Cluster_Demo', 'Cluster_SVC',\n",
       "       'Cluster_Streaming', 'Cluster_Tenure', 'Cluster_Payment',\n",
       "       'Cluster_Profit', 'Cluster_Overall', 'Cluster_Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant variables for prediction (cluster) \n",
    "columns_to_remove=[col for col in all_data.columns if col.startswith('Cluster_')]\n",
    "all_data.drop(columns=columns_to_remove, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scenarios generated in feature selection\n",
    "scenario1_td = pd.read_csv('data/processed/scenario1.csv')\n",
    "scenario2_td = pd.read_csv('data/processed/scenario2.csv')\n",
    "\n",
    "# Other scenarios created in this notebook\n",
    "\n",
    "scenario3 = all_data[['Senior Citizen','Dependents','Referred a Friend','Internet Service','Internet Type_Fiber Optic','Online Security','Offer_Offer E',\n",
    "                     'Offer_Offer A','Premium Tech Support','Unlimited Data','Contract_Month-to-Month','Paperless Billing','Payment Method_Credit Card', 'Churn Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Customer ID', 'Satisfaction Score', 'Churn Score',\n",
      "       'Contract_Month-to-Month', 'Number of Referrals', 'Online Security',\n",
      "       'Monthly Charge'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(scenario1_td.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete Churn Score from scenario 1\n",
    "scenario1_td.drop(columns=['Churn Score'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Data Split\n",
    "> Train-Test split<p>\n",
    "> Train data in predictors (X) and target variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scenario to test\n",
    "df = scenario1_td.copy()\n",
    "df.set_index(\"Customer ID\", inplace=True)\n",
    "\n",
    "# Split\n",
    "X_total = df\n",
    "y_total = all_data[[\"Customer ID\", \"Churn Label\"]]\n",
    "y_total.set_index(\"Customer ID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data into Train and test with 20% test Data. Stratify dut to unbalance Dataset. (Only 27% Churn)\n",
    "X_train_total, X_test, y_train_total, y_test = train_test_split(X_total, y_total, test_size=0.20, random_state=1, stratify=y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to append the metrics of all the models\n",
    "models =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline X_train\n",
    "### 2.1 Logistic Regression - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.945, 0.946, 0.946, 0.947, 0.944]\n",
      "Mean Accuracy: 0.946\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.892, 0.895, 0.895, 0.898, 0.892]\n",
      "Mean F1: 0.894\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.942, 0.94, 0.941, 0.946, 0.956]\n",
      "Mean Accuracy: 0.945\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.884, 0.883, 0.886, 0.895, 0.916]\n",
      "Mean F1: 0.893\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling - scenario 1 already scaled\n",
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_LR = LogisticRegression()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_LR.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_LR.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_LR.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.952\n",
      "Test F1 Scores: 0.906\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_LR.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_LR.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = {\"Model\": \"Logistic Regression\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision Tree - Train and Validation Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.942, 0.939, 0.939, 0.938, 0.935]\n",
      "Mean Accuracy: 0.939\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.877, 0.871, 0.871, 0.868, 0.86]\n",
      "Mean F1: 0.869\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.926, 0.937, 0.936, 0.941, 0.954]\n",
      "Mean Accuracy: 0.939\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.839, 0.865, 0.863, 0.874, 0.905]\n",
      "Mean F1: 0.869\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_DT = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_DT.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_DT.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_DT.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision Tree - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.94\n",
      "Test F1 Scores: 0.873\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_DT.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_DT.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = {\"Model\": \"Decision Tree\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Random Forest - Train and Validation Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.942, 0.939, 0.939, 0.938, 0.935]\n",
      "Mean Accuracy: 0.939\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.877, 0.871, 0.871, 0.868, 0.86]\n",
      "Mean F1: 0.869\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.926, 0.937, 0.936, 0.941, 0.954]\n",
      "Mean Accuracy: 0.939\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.839, 0.865, 0.863, 0.874, 0.905]\n",
      "Mean F1: 0.869\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_RF = RandomForestClassifier(max_depth=3)\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_DT.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_DT.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_DT.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Random Forest - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.94\n",
      "Test F1 Scores: 0.873\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_RF.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_RF.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = {\"Model\": \"Random Forest\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 SVC - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.948, 0.948, 0.95, 0.949, 0.946]\n",
      "Mean Accuracy: 0.948\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.902, 0.903, 0.905, 0.904, 0.9]\n",
      "Mean F1: 0.903\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.952, 0.945, 0.946, 0.941, 0.955]\n",
      "Mean Accuracy: 0.948\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.907, 0.898, 0.897, 0.889, 0.916]\n",
      "Mean F1: 0.901\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_SVC = SVC()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_SVC.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_SVC.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_SVC.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 SVC - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.952\n",
      "Test F1 Scores: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_SVC.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_SVC.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcc = {\"Model\": \"SVC\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(svcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Gaussian - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.935, 0.934, 0.931, 0.936, 0.933]\n",
      "Mean Accuracy: 0.934\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.879, 0.878, 0.874, 0.882, 0.876]\n",
      "Mean F1: 0.878\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.937, 0.93, 0.938, 0.929, 0.933]\n",
      "Mean Accuracy: 0.933\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.883, 0.871, 0.885, 0.869, 0.877]\n",
      "Mean F1: 0.877\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_GA = GaussianNB()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_GA.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_GA.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_GA.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Gaussian - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.938\n",
      "Test F1 Scores: 0.887\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_GA.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_GA.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = {\"Model\": \"Gaussian\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 KNN - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.962, 0.962, 0.962, 0.963, 0.96]\n",
      "Mean Accuracy: 0.962\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.927, 0.928, 0.927, 0.929, 0.923]\n",
      "Mean F1: 0.927\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.943, 0.941, 0.941, 0.937, 0.948]\n",
      "Mean Accuracy: 0.942\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.888, 0.887, 0.887, 0.878, 0.902]\n",
      "Mean F1: 0.888\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_KNN = KNeighborsClassifier()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_KNN.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_KNN.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_KNN.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 KNN - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.943\n",
      "Test F1 Scores: 0.891\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_KNN.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_KNN.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = {\"Model\": \"KNN\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Gradient Boosting - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.958, 0.957, 0.957, 0.96, 0.955]\n",
      "Mean Accuracy: 0.957\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.921, 0.917, 0.917, 0.924, 0.914]\n",
      "Mean F1: 0.919\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.948, 0.949, 0.948, 0.943, 0.957]\n",
      "Mean Accuracy: 0.949\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.898, 0.903, 0.899, 0.89, 0.92]\n",
      "Mean F1: 0.902\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_GB = GradientBoostingClassifier()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_GB.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_GB.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_GB.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Gradient Boosting - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.955\n",
      "Test F1 Scores: 0.913\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_GB.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_GB.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = {\"Model\": \"Gradient Boosting\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 MLP - Train and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.947, 0.949, 0.947, 0.948, 0.946]\n",
      "Mean Accuracy: 0.947\n",
      "\n",
      "Training F1 Score:\n",
      "Cross-Validation F1 Scores: [0.899, 0.904, 0.898, 0.9, 0.899]\n",
      "Mean F1: 0.9\n",
      "\n",
      "Validation Accuracy:\n",
      "Cross-Validation Accuracy Scores: [0.944, 0.945, 0.945, 0.947, 0.956]\n",
      "Mean Accuracy: 0.947\n",
      "\n",
      "Validation F1 Score:\n",
      "Cross-Validation F1 Scores: [0.89, 0.897, 0.895, 0.898, 0.919]\n",
      "Mean F1: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Create StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model_MLP = MLPClassifier()\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "train_accuracy_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# Initialize variables to store Validation results\n",
    "val_accuracy_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_idx, val_idx in k_fold.split(X_train_total, y_train_total):\n",
    "    X_train, X_val = X_train_total.iloc[train_idx], X_train_total.iloc[val_idx]\n",
    "    y_train, y_val = y_train_total.iloc[train_idx], y_train_total.iloc[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model_MLP.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the training set  - To check potential overfitting\n",
    "    y_train_pred = model_MLP.predict(X_train)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f1_scores.append(round(f1,3))\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = model_MLP.predict(X_val)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracy_scores.append(round(accuracy,3))\n",
    "    \n",
    "    #F1 Score \n",
    "    f1 = f1_score(y_val, y_val_pred)\n",
    "    val_f1_scores.append(round(f1,3))\n",
    "\n",
    "#Training\n",
    "# Print accuracy results\n",
    "print(\"Training Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {train_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(train_accuracy_scores) / len(train_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Training F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {train_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(train_f1_scores) / len(train_f1_scores),3)}\\n')\n",
    "\n",
    "#Validation\n",
    "# Print accuracy results\n",
    "print(\"Validation Accuracy:\")\n",
    "print(f'Cross-Validation Accuracy Scores: {val_accuracy_scores}')\n",
    "print(f'Mean Accuracy: {round(sum(val_accuracy_scores) / len(val_accuracy_scores),3)}\\n')\n",
    "\n",
    "# Print F1 results\n",
    "print(\"Validation F1 Score:\")\n",
    "print(f'Cross-Validation F1 Scores: {val_f1_scores}')\n",
    "print(f'Mean F1: {round(sum(val_f1_scores) / len(val_f1_scores),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 MLP - Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Scores: 0.95\n",
      "Test F1 Scores: 0.905\n"
     ]
    }
   ],
   "source": [
    "# Fit Model to total Training Data\n",
    "model_MLP.fit(X_train_total, y_train_total)\n",
    "\n",
    "# Make predictions on the Test set\n",
    "y_test_pred = model_MLP.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the Test set\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "#Print Test Scores\n",
    "print(f'Test Accuracy Scores: {round(accuracy,3)}')\n",
    "print(f'Test F1 Scores: {round(f1,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = {\"Model\": \"MLP\", \n",
    "      \"Accuracy Training\": round(sum(train_accuracy_scores) / len(train_accuracy_scores),3),\n",
    "      \"Accuracy Validation\": round(sum(val_accuracy_scores) / len(val_accuracy_scores),3),\n",
    "      \"Accuracy Test\": round(accuracy,3),\n",
    "      \"F1 Training\": round(sum(train_f1_scores) / len(train_f1_scores),3),\n",
    "      \"F1 Validation\": round(sum(val_f1_scores) / len(val_f1_scores),3),\n",
    "      \"F1 Test\": round(f1,3)}\n",
    "\n",
    "models.append(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coonvert List of Models Metrics to DF\n",
    "models_df = pd.DataFrame(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Training</th>\n",
       "      <th>Accuracy Validation</th>\n",
       "      <th>Accuracy Test</th>\n",
       "      <th>F1 Training</th>\n",
       "      <th>F1 Validation</th>\n",
       "      <th>F1 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy Training  Accuracy Validation  Accuracy Test  \\\n",
       "0  Logistic Regression              0.946                0.945          0.952   \n",
       "1        Decision Tree              0.939                0.939          0.940   \n",
       "2        Random Forest              0.939                0.939          0.940   \n",
       "3                  SVC              0.948                0.948          0.952   \n",
       "4             Gaussian              0.934                0.933          0.938   \n",
       "5                  KNN              0.962                0.942          0.943   \n",
       "6    Gradient Boosting              0.957                0.949          0.955   \n",
       "7                  MLP              0.947                0.947          0.950   \n",
       "\n",
       "   F1 Training  F1 Validation  F1 Test  \n",
       "0        0.894          0.893    0.906  \n",
       "1        0.869          0.869    0.873  \n",
       "2        0.869          0.869    0.873  \n",
       "3        0.903          0.901    0.910  \n",
       "4        0.878          0.877    0.887  \n",
       "5        0.927          0.888    0.891  \n",
       "6        0.919          0.902    0.913  \n",
       "7        0.900          0.900    0.905  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decision Trees:\n",
    "Intuitive and easy to understand.\n",
    "Can capture complex relationships in the data.\n",
    "\n",
    "> Random Forest:\n",
    "Ensemble method built on decision trees.\n",
    "Generally more robust and accurate than individual trees.\n",
    "\n",
    "> Support Vector Machines (SVM):\n",
    "Effective in high-dimensional spaces.\n",
    "Works well when there is a clear margin of separation between classes.\n",
    "\n",
    "> Naive Bayes:\n",
    "Assumes independence between features.\n",
    "Fast and can perform well on certain types of data.\n",
    "\n",
    "> K-Nearest Neighbors (KNN):\n",
    "Instance-based learning.\n",
    "Simple and easy to understand.\n",
    "\n",
    "> Gradient Boosting (e.g., XGBoost, LightGBM, AdaBoost):\n",
    "Builds a strong predictive model by combining weak models.\n",
    "Often produces very accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 RandomSearch - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Best Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsample</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_estimators</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max_features</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max_depth</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Score</td>\n",
       "      <td>0.905923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Parameter Best Result\n",
       "0          subsample         0.5\n",
       "0       n_estimators        50.0\n",
       "0  min_samples_split        10.0\n",
       "0   min_samples_leaf         1.0\n",
       "0       max_features        sqrt\n",
       "0          max_depth           3\n",
       "0      learning_rate         0.1\n",
       "0         Best Score    0.905923"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Create the Gradient Boosting model (without specifying hyperparameters)\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Define the parameter space for random search\n",
    "parameter_space_random = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'subsample': np.arange(0.1, 1.1, 0.1),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=gb_model, param_distributions=parameter_space_random,\n",
    "                                    scoring='f1', cv=5, random_state=42)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the data\n",
    "random_search.fit(X_total, y_total)\n",
    "\n",
    "# Print the best parameters\n",
    "#print(\"Best Parameters: \", random_search.best_params_)\n",
    "\n",
    "# Extract the best parameters and their scores from RandomizedSearchCV\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_rs_gb = pd.DataFrame(columns=['Parameter', 'Best Result'])\n",
    "\n",
    "# Add the best parameters and scores to the DataFrame\n",
    "for param, value in best_params_random.items():\n",
    "    results_rs_gb = pd.concat([results_rs_gb, pd.DataFrame({'Parameter': [param], 'Best Result': [value]})])\n",
    "\n",
    "# Add the best score to the DataFrame\n",
    "results_rs_gb = pd.concat([results_rs_gb, pd.DataFrame({'Parameter': ['Best Score'], 'Best Result': [best_score_random]})])\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_rs_gb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 GridSearch - Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 50, 'subsample': 0.7}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Best Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max_depth</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max_features</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_estimators</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsample</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Score</td>\n",
       "      <td>0.908797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Parameter Best Result\n",
       "0      learning_rate         0.1\n",
       "0          max_depth         3.0\n",
       "0       max_features        sqrt\n",
       "0  min_samples_split          10\n",
       "0       n_estimators          50\n",
       "0          subsample         0.7\n",
       "0         Best Score    0.908797"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Gradient Boosting model (without specifying hyperparameters)\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "parameter_grid = {\n",
    "    'n_estimators': [50,60,40],\n",
    "    'learning_rate': [0.1,0.09,0.1],\n",
    "    'max_depth': [2.5,2.7,3,3.1,3.2],\n",
    "    'subsample': [0.5,0.6,0.4,.03,0.7],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_split': [9,11,10],\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=parameter_grid,\n",
    "                           scoring='f1', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_total, y_total)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_gs_gb = pd.DataFrame(columns=['Parameter', 'Best Result'])\n",
    "\n",
    "# Add the best parameters and scores to the DataFrame\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    results_gs_gb = pd.concat([results_gs_gb, pd.DataFrame({'Parameter': [param], 'Best Result': [value]})])\n",
    "\n",
    "# Add the best score to the DataFrame\n",
    "results_gs_gb= pd.concat([results_gs_gb, pd.DataFrame({'Parameter': ['Best Score'], 'Best Result': [grid_search.best_score_]})])\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_gs_gb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model - GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_gb = GradientBoostingClassifier(\n",
    "    n_estimators=60,\n",
    "    learning_rate=0.09,\n",
    "    max_depth=3,\n",
    "    subsample=0.5,\n",
    "    max_features='sqrt',\n",
    "    min_samples_split=10,\n",
    "    n_iter_no_change=2000,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 RandomSearch - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Best Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kernel</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gamma</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Score</td>\n",
       "      <td>0.880042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Parameter Best Result\n",
       "0        kernel      linear\n",
       "0         gamma      0.0001\n",
       "0  class_weight        None\n",
       "0             C          10\n",
       "0    Best Score    0.880042"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Support Vector Classification (SVC) model (without specifying hyperparameters)\n",
    "model_SVC = SVC()\n",
    "\n",
    "# Define the parameter space for random search\n",
    "parameter_space_random = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1e-3, 1e-4],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=model_SVC, param_distributions=parameter_space_random,\n",
    "                                    scoring='f1', cv=5, random_state=42)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the data\n",
    "random_search.fit(X_total, y_total)  # Make sure X_total and y_total are defined\n",
    "\n",
    "# Extract the best parameters and their scores from RandomizedSearchCV\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_rs_svc = pd.DataFrame(columns=['Parameter', 'Best Result'])\n",
    "\n",
    "# Add the best parameters and scores to the DataFrame\n",
    "for param, value in best_params_random.items():\n",
    "    results_rs_svc = pd.concat([results_rs_svc, pd.DataFrame({'Parameter': [param], 'Best Result': [value]})])\n",
    "\n",
    "# Add the best score to the DataFrame\n",
    "results_rs_svc = pd.concat([results_rs_svc, pd.DataFrame({'Parameter': ['Best Score'], 'Best Result': [best_score_random]})])\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_rs_svc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 GridSearch - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 11, 'class_weight': None, 'gamma': 0.0001, 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Best Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class_weight</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gamma</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kernel</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Score</td>\n",
       "      <td>0.880339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Parameter Best Result\n",
       "0             C          11\n",
       "0  class_weight        None\n",
       "0         gamma      0.0001\n",
       "0        kernel      linear\n",
       "0    Best Score    0.880339"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Support Vector Classification (SVC) model (without specifying hyperparameters)\n",
    "model_SVC = SVC()\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "parameter_space_grid = {\n",
    "    'C': [11, 10, 12],\n",
    "    'gamma': [1e-4, 2e-4, 0.5e-4],\n",
    "    'kernel': ['linear'],\n",
    "    'class_weight': [None],\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model_SVC, param_grid=parameter_space_grid,\n",
    "                           scoring='f1', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_total, y_total)  # Make sure X_total and y_total are defined\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_gs_scv = pd.DataFrame(columns=['Parameter', 'Best Result'])\n",
    "\n",
    "# Add the best parameters and scores to the DataFrame\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    results_gs_scv = pd.concat([results_gs_scv, pd.DataFrame({'Parameter': [param], 'Best Result': [value]})])\n",
    "\n",
    "# Add the best score to the DataFrame\n",
    "results_gs_scv = pd.concat([results_gs_scv, pd.DataFrame({'Parameter': ['Best Score'], 'Best Result': [grid_search.best_score_]})])\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_gs_scv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_svc = SVC(\n",
    "    C=11,\n",
    "    class_weight=None,\n",
    "    gamma=0.0001,\n",
    "    kernel='linear',\n",
    "    max_iter=2000,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 RandomSearch - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Best Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>solver</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hidden_layer_sizes</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>activation</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Score</td>\n",
       "      <td>0.90335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Parameter   Best Result\n",
       "0              solver          adam\n",
       "0       learning_rate      constant\n",
       "0  hidden_layer_sizes  (50, 50, 50)\n",
       "0               alpha        0.0001\n",
       "0          activation          relu\n",
       "0          Best Score       0.90335"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Multi-Layer Perceptron (MLP) model (without specifying hyperparameters)\n",
    "model_MLP = MLPClassifier()\n",
    "\n",
    "# Define the parameter space for random search\n",
    "parameter_space_random = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=model_MLP, param_distributions=parameter_space_random,\n",
    "                                    scoring='f1', cv=5, random_state=42)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the data\n",
    "random_search.fit(X_total, y_total)  # Make sure X_total and y_total are defined\n",
    "\n",
    "# Extract the best parameters and their scores from RandomizedSearchCV\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_rs_mlp = pd.DataFrame(columns=['Parameter', 'Best Result'])\n",
    "\n",
    "# Add the best parameters and scores to the DataFrame\n",
    "for param, value in best_params_random.items():\n",
    "    results_rs_mlp = pd.concat([results_rs_mlp, pd.DataFrame({'Parameter': [param], 'Best Result': [value]})])\n",
    "\n",
    "# Add the best score to the DataFrame\n",
    "results_rs_mlp = pd.concat([results_rs_mlp, pd.DataFrame({'Parameter': ['Best Score'], 'Best Result': [best_score_random]})])\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_rs_mlp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 GridSearch - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50, 50, 50), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Best Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>activation</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hidden_layer_sizes</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>adaptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>solver</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Score</td>\n",
       "      <td>0.897157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Parameter   Best Result\n",
       "0          activation          relu\n",
       "0               alpha        0.0001\n",
       "0  hidden_layer_sizes  (50, 50, 50)\n",
       "0       learning_rate      adaptive\n",
       "0              solver          adam\n",
       "0          Best Score      0.897157"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Support Vector Classification (SVC) model (without specifying hyperparameters)\n",
    "model_MLP = MLPClassifier()\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "parameter_space_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.0002,0.00009],\n",
    "    'learning_rate': ['adaptive'],\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model_MLP, param_grid=parameter_space_grid,\n",
    "                           scoring='f1', cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_total, y_total)  # Make sure X_total and y_total are defined\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_gs_mlp = pd.DataFrame(columns=['Parameter', 'Best Result'])\n",
    "\n",
    "# Add the best parameters and scores to the DataFrame\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    results_gs_mlp = pd.concat([results_gs_mlp, pd.DataFrame({'Parameter': [param], 'Best Result': [value]})])\n",
    "\n",
    "# Add the best score to the DataFrame\n",
    "results_gs_mlp = pd.concat([results_gs_mlp, pd.DataFrame({'Parameter': ['Best Score'], 'Best Result': [grid_search.best_score_]})])\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_gs_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_mlp = MLPClassifier(\n",
    "    activation='relu',\n",
    "    alpha=0.0001,\n",
    "    hidden_layer_sizes=(50, 50, 50),\n",
    "    learning_rate='adaptive',\n",
    "    solver='adam',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_models(df, model):\n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 99, shuffle = True)\n",
    "    X = df\n",
    "    y = all_data['Churn Label'].copy()\n",
    "    score_train, score_val = [],[]\n",
    "        \n",
    "    # perform the cross-validation    \n",
    "    for train_index, val_index in skf.split(X,y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        \n",
    "        # Apply model\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions_train = model.predict(X_train)\n",
    "        predictions_val = model.predict(X_val)\n",
    "        score_train.append(f1_score(y_train, predictions_train))\n",
    "        score_val.append(f1_score(y_val, predictions_val))\n",
    "\n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_val = round(np.mean(score_val),3)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_val = round(np.std(score_val),2)\n",
    "\n",
    "    return avg_train, std_train, avg_val, std_val\n",
    "\n",
    "def show_results(df, data, *args):\n",
    "    count = 0\n",
    "    # for each instance of model passed as argument\n",
    "    for arg in args:\n",
    "        avg_train, std_train, avg_val, std_val = select_best_models(data, arg)\n",
    "        # store the results in the right row\n",
    "        df.iloc[count] = str(avg_train) + '+/-' + str(std_train), str(avg_val) + '+/-' + str(std_val)\n",
    "        count+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Best GB</th>\n",
       "      <td>0.909+/-0.0</td>\n",
       "      <td>0.909+/-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best SVC</th>\n",
       "      <td>0.885+/-0.02</td>\n",
       "      <td>0.878+/-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best MLP</th>\n",
       "      <td>0.903+/-0.01</td>\n",
       "      <td>0.902+/-0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Train    Validation\n",
       "Best GB    0.909+/-0.0  0.909+/-0.01\n",
       "Best SVC  0.885+/-0.02  0.878+/-0.02\n",
       "Best MLP  0.903+/-0.01  0.902+/-0.01"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_models = pd.DataFrame(columns = ['Train','Validation'], index = ['Best GB','Best SVC', 'Best MLP'])\n",
    "show_results(df_final_models, df, final_model_gb, final_model_svc, final_model_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
